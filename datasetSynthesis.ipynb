{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Habitat suitability for Red Pandas -- Dataset Synthesis\n",
    "\n",
    "# Synthetic Habitat Suitability Dataset Creation Summary\n",
    "\n",
    "A synthetic dataset has been created to model the habitat suitability for pandas. The dataset comprises 100,000 samples, each with the following variables:\n",
    "\n",
    "- `Altitude`: Generated from a uniform distribution ranging from 1200 to 3400 meters.\n",
    "- `Distance_from_Human_Paths`: Generated from an exponential distribution, with a mean distance of 500 meters.\n",
    "- `Livestock_Density`: Generated from a gamma distribution to represent skewed data, with a shape parameter of 2 and a scale of 0.5.\n",
    "- `Vegetation_Diversity_Index`: Generated from a uniform distribution between 0 and 1.\n",
    "- `Water_Source_Availability`: Binary variable generated with a preference for '1' (70%) over '0' (30%).\n",
    "- `Human_Disturbance_Index`: Generated from a uniform distribution between 0 and 1.\n",
    "- `Slope`: Generated from a uniform distribution between 0 and 30 degrees.\n",
    "- `Annual_Rainfall`: Generated from a normal distribution centered at 1500 mm with a standard deviation of 250 mm.\n",
    "\n",
    "Correlations and noise have been introduced to reflect ecological relationships:\n",
    "\n",
    "1. **Altitude and Bamboo Coverage**: A positive linear relationship with 10% noise added.\n",
    "2. **Livestock Density and Vegetation Diversity Index**: An inverse relationship modified by the exponential of negative livestock density, with 5% noise added.\n",
    "3. **Water Source Availability and Annual Rainfall**: A conditional relationship where higher rainfall increases the likelihood of water availability, with 10% noise introduced by inverting the availability status.\n",
    "4. **Distance from Human Paths and Human Disturbance Index**: An inverse relationship where greater distance from paths lowers the disturbance index, with 10% noise added.\n",
    "5. **Slope and Bamboo Coverage**: A conditional relationship where slopes under 20 degrees do not affect bamboo coverage, while steeper slopes reduce coverage by half, with 10% noise added.\n",
    "\n",
    "The `Suitable` variable is defined based on a K-Means Clustering Algortihm, and artificially manipulated to have 30% of rows identified as suitable.\n",
    "\n",
    "Lastly, `Mean_Annual_Temperature` is derived from altitude with a simple linear relationship and added noise, to reflect the decrease in temperature with increasing altitude.\n",
    "\n",
    "The dataset synthesis process includes random noise to simulate natural variability and to prevent perfect correlations, aiming to create a realistic dataset for training predictive models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features values generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Distance_from_Human_Paths</th>\n",
       "      <th>Livestock_Density</th>\n",
       "      <th>Vegetation_Diversity_Index</th>\n",
       "      <th>Water_Source_Availability</th>\n",
       "      <th>Human_Disturbance_Index</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Annual_Rainfall</th>\n",
       "      <th>Bamboo_Coverage</th>\n",
       "      <th>Mean_Annual_Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023.988261</td>\n",
       "      <td>434.678578</td>\n",
       "      <td>0.634095</td>\n",
       "      <td>0.319653</td>\n",
       "      <td>0</td>\n",
       "      <td>1.025552</td>\n",
       "      <td>1.902428</td>\n",
       "      <td>1364.685583</td>\n",
       "      <td>30.270545</td>\n",
       "      <td>9.912647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3291.571474</td>\n",
       "      <td>374.299977</td>\n",
       "      <td>0.132676</td>\n",
       "      <td>0.604097</td>\n",
       "      <td>1</td>\n",
       "      <td>1.032245</td>\n",
       "      <td>16.484248</td>\n",
       "      <td>1616.727901</td>\n",
       "      <td>71.382519</td>\n",
       "      <td>1.701986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2810.386672</td>\n",
       "      <td>216.189749</td>\n",
       "      <td>0.477984</td>\n",
       "      <td>0.157106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.963946</td>\n",
       "      <td>29.466434</td>\n",
       "      <td>1373.229653</td>\n",
       "      <td>31.969303</td>\n",
       "      <td>6.258988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2517.048665</td>\n",
       "      <td>339.831903</td>\n",
       "      <td>0.386706</td>\n",
       "      <td>0.560503</td>\n",
       "      <td>1</td>\n",
       "      <td>1.142016</td>\n",
       "      <td>9.966878</td>\n",
       "      <td>1747.708413</td>\n",
       "      <td>50.076009</td>\n",
       "      <td>7.423174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1543.241009</td>\n",
       "      <td>227.141237</td>\n",
       "      <td>0.654869</td>\n",
       "      <td>0.349722</td>\n",
       "      <td>1</td>\n",
       "      <td>1.050573</td>\n",
       "      <td>10.647234</td>\n",
       "      <td>1500.073131</td>\n",
       "      <td>17.449099</td>\n",
       "      <td>12.331676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Altitude  Distance_from_Human_Paths  Livestock_Density  \\\n",
       "0  2023.988261                 434.678578           0.634095   \n",
       "1  3291.571474                 374.299977           0.132676   \n",
       "2  2810.386672                 216.189749           0.477984   \n",
       "3  2517.048665                 339.831903           0.386706   \n",
       "4  1543.241009                 227.141237           0.654869   \n",
       "\n",
       "   Vegetation_Diversity_Index  Water_Source_Availability  \\\n",
       "0                    0.319653                          0   \n",
       "1                    0.604097                          1   \n",
       "2                    0.157106                          0   \n",
       "3                    0.560503                          1   \n",
       "4                    0.349722                          1   \n",
       "\n",
       "   Human_Disturbance_Index      Slope  Annual_Rainfall  Bamboo_Coverage  \\\n",
       "0                 1.025552   1.902428      1364.685583        30.270545   \n",
       "1                 1.032245  16.484248      1616.727901        71.382519   \n",
       "2                 0.963946  29.466434      1373.229653        31.969303   \n",
       "3                 1.142016   9.966878      1747.708413        50.076009   \n",
       "4                 1.050573  10.647234      1500.073131        17.449099   \n",
       "\n",
       "   Mean_Annual_Temperature  \n",
       "0                 9.912647  \n",
       "1                 1.701986  \n",
       "2                 6.258988  \n",
       "3                 7.423174  \n",
       "4                12.331676  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples in the dataset\n",
    "n_samples = 100000\n",
    "\n",
    "# Generate the synthetic data\n",
    "data = pd.DataFrame({\n",
    "    'Altitude': np.random.uniform(1200, 3400, n_samples),  # Uniform distribution\n",
    "    'Distance_from_Human_Paths': np.random.exponential(500, n_samples),  # Exponential distribution\n",
    "    'Livestock_Density': np.random.gamma(2, 0.5, n_samples),  # Gamma distribution for skewed data\n",
    "    'Vegetation_Diversity_Index': np.random.uniform(0, 1, n_samples),  # Uniform distribution\n",
    "    # This one is not good, needs to be corrected\n",
    "    'Water_Source_Availability': np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),  # Binary, with more 1s\n",
    "    'Human_Disturbance_Index': np.random.uniform(0, 1, n_samples),  # Uniform distribution\n",
    "    'Slope': np.random.uniform(0, 30, n_samples),  # Uniform distribution\n",
    "    'Annual_Rainfall': np.random.normal(1500, 250, n_samples)  # Normal distribution\n",
    "})\n",
    "\n",
    "# Add noise function\n",
    "def add_noise(factor, size):\n",
    "    return np.random.normal(1, factor, size)\n",
    "\n",
    "# Correlation 1: Altitude and Bamboo Coverage (with noise)\n",
    "data['Bamboo_Coverage'] = np.interp(data['Altitude'], [1200, 3400], [0, 100])\n",
    "data['Bamboo_Coverage'] *= add_noise(0.1, n_samples)  # Adding 10% noise\n",
    "\n",
    "# Correlation 2: Livestock Density and Vegetation Diversity Index (with noise)\n",
    "data['Vegetation_Diversity_Index'] *= np.exp(-data['Livestock_Density'])\n",
    "data['Vegetation_Diversity_Index'] *= add_noise(0.05, n_samples)  # Adding 5% noise\n",
    "\n",
    "# Correlation 3: Water Source Availability and Annual Rainfall (with noise)\n",
    "data['Water_Source_Availability'] = np.where(data['Annual_Rainfall'] > data['Annual_Rainfall'].mean(), 1, 0)\n",
    "data['Water_Source_Availability'] = np.where(np.random.rand(n_samples) < 0.1, 1 - data['Water_Source_Availability'], data['Water_Source_Availability'])  # Inverting 10% to add noise\n",
    "\n",
    "# Correlation 4: Distance from Human Paths and Human Disturbance Index (with noise)\n",
    "data['Human_Disturbance_Index'] = np.interp(data['Distance_from_Human_Paths'], [0, max(data['Distance_from_Human_Paths'])], [1, 0])\n",
    "data['Human_Disturbance_Index'] *= add_noise(0.1, n_samples)  # Adding 10% noise\n",
    "\n",
    "# Correlation 5: Slope and Bamboo Coverage (with noise)\n",
    "data['Bamboo_Coverage'] *= np.where(data['Slope'] < 20, 1, 0.5)  # Reduce bamboo coverage on steep slopes\n",
    "data['Bamboo_Coverage'] *= add_noise(0.1, n_samples)  # Adding 10% noise\n",
    "\n",
    "# Mean Annual Temperature is derived with some noise, considering its correlation with Altitude\n",
    "data['Mean_Annual_Temperature'] = 20 - (data['Altitude'] / 200)  # Simplified linear relation\n",
    "data['Mean_Annual_Temperature'] += np.random.normal(0, 1, n_samples)  # Adding noise\n",
    "\n",
    "# Output the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples in the dataset\n",
    "n_samples = 10000\n",
    "\n",
    "# Generate the synthetic data\n",
    "data = pd.DataFrame({\n",
    "    'Altitude': np.random.uniform(1200, 3400, n_samples),  # Uniform distribution\n",
    "    'Distance_from_Human_Paths': np.random.exponential(500, n_samples),  # Exponential distribution\n",
    "    'Livestock_Density': np.random.gamma(2, 0.5, n_samples),  # Gamma distribution for skewed data\n",
    "    'Vegetation_Diversity_Index': np.random.uniform(0, 1, n_samples),  # Uniform distribution\n",
    "    'Water_Source_Availability': np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),  # Binary, with more 1s\n",
    "    'Human_Disturbance_Index': np.random.uniform(0, 1, n_samples),  # Uniform distribution\n",
    "    'Slope': np.random.uniform(0, 30, n_samples),  # Uniform distribution\n",
    "    'Annual_Rainfall': np.random.normal(1500, 250, n_samples)  # Normal distribution\n",
    "})\n",
    "\n",
    "# Noise and transformations functions\n",
    "def add_noise(factor, size):\n",
    "    return np.random.normal(1, factor, size)\n",
    "\n",
    "def add_complex_noise(data, feature, noise_level, correlation_feature=None, correlation_func=None):\n",
    "    noise = np.random.normal(1, noise_level, data.shape[0])\n",
    "    if correlation_feature is not None and correlation_func is not None:\n",
    "        correlation = correlation_func(data[correlation_feature])\n",
    "        return data[feature] * noise * correlation\n",
    "    return data[feature] * noise\n",
    "\n",
    "def add_outliers(data, feature, proportion, scale):\n",
    "    indices = np.random.choice(data.index, size=int(proportion * len(data)), replace=False)\n",
    "    outliers = np.random.normal(scale=np.std(data[feature]) * scale, size=indices.shape[0])\n",
    "    data.loc[indices, feature] += outliers\n",
    "\n",
    "# Correlations functions\n",
    "def correlate_with_altitude(data, feature_name, base_value, scale_factor, noise_std=0):\n",
    "    # Elevation-dependent feature with added noise\n",
    "    data[feature_name] = base_value - (data['Altitude'] / scale_factor)\n",
    "    data[feature_name] += np.random.normal(0, noise_std, len(data))\n",
    "    data[feature_name] = data[feature_name].clip(lower=0)  # Ensure values are not negative\n",
    "\n",
    "def correlate_with_water_source(data, feature_name, base_value, variation_factor, noise_std=0):\n",
    "    # Feature varies with water source availability\n",
    "    data[feature_name] = data['Water_Source_Availability'].apply(lambda x: base_value + np.random.normal(variation_factor if x == 1 else -variation_factor, noise_std))\n",
    "\n",
    "def correlate_with_human_disturbance(data, feature_name, base_value, scale_factor, noise_std=0):\n",
    "    # Feature decreases with more human disturbance\n",
    "    data[feature_name] = base_value - (data['Human_Disturbance_Index'] * scale_factor)\n",
    "    data[feature_name] += np.random.normal(0, noise_std, len(data))\n",
    "    data[feature_name] = data[feature_name].clip(lower=0)\n",
    "\n",
    "# New Correlations\n",
    "def correlate_slope_with_water(data):\n",
    "    data['Water_Source_Availability'] = np.where(data['Slope'] > 15, 0, data['Water_Source_Availability'])\n",
    "\n",
    "def correlate_distance_with_vegetation(data):\n",
    "    data['Vegetation_Diversity_Index'] *= np.exp(-data['Distance_from_Human_Paths'] / 1000)\n",
    "\n",
    "def correlate_livestock_with_human_disturbance(data):\n",
    "    data['Livestock_Density'] *= 1 + (data['Human_Disturbance_Index'] * 0.5)\n",
    "\n",
    "def correlate_altitude_with_bamboo(data):\n",
    "    data['Bamboo_Coverage'] = np.interp(data['Altitude'], [1200, 3400], [100, 0])\n",
    "    data['Bamboo_Coverage'] *= add_noise(0.25, n_samples)\n",
    "\n",
    "def correlate_rainfall_with_vegetation(data):\n",
    "    # Assuming that a certain level of rainfall is beneficial but too much might be detrimental\n",
    "    optimal_rainfall = 1500\n",
    "    data['Vegetation_Diversity_Index'] *= np.where(\n",
    "        data['Annual_Rainfall'] < optimal_rainfall,\n",
    "        # Scale positively with rainfall up to the optimal point\n",
    "        data['Annual_Rainfall'] / optimal_rainfall,\n",
    "        # Beyond the optimal point, start scaling negatively\n",
    "        optimal_rainfall / data['Annual_Rainfall']\n",
    "    )\n",
    "\n",
    "# Correlation between Altitude and Livestock Density\n",
    "def correlate_altitude_with_livestock(data):\n",
    "    # Assuming livestock density decreases by 0.2% for each meter increase in altitude\n",
    "    data['Livestock_Density'] *= (1 - data['Altitude'] * 0.002 / 100)\n",
    "\n",
    "# Correlation between Human Disturbance Index and Water Source Availability\n",
    "def correlate_human_disturbance_with_water(data):\n",
    "    # Assuming the presence of water is reduced by 50% in areas with high human disturbance\n",
    "    data['Water_Source_Availability'] *= np.where(\n",
    "        data['Human_Disturbance_Index'] > 0.5,\n",
    "        0.5,\n",
    "        1\n",
    "    )\n",
    "\n",
    "# Applying new correlations\n",
    "correlate_rainfall_with_vegetation(data)\n",
    "correlate_altitude_with_livestock(data)\n",
    "correlate_human_disturbance_with_water(data)\n",
    "correlate_slope_with_water(data)\n",
    "correlate_distance_with_vegetation(data)\n",
    "correlate_livestock_with_human_disturbance(data)\n",
    "correlate_altitude_with_bamboo(data)\n",
    "correlate_with_altitude(data, 'Mean_Annual_Temperature', base_value=30, scale_factor=300, noise_std=1)\n",
    "correlate_with_water_source(data, 'Vegetation_Diversity_Index', base_value=0.5, variation_factor=0.3, noise_std=0.05)\n",
    "correlate_with_human_disturbance(data, 'Livestock_Density', base_value=5, scale_factor=3, noise_std=0.1)\n",
    "\n",
    "\n",
    "# Applying correlations and noise\n",
    "data['Bamboo_Coverage'] = np.interp(data['Altitude'], [1200, 3400], [0, 100])\n",
    "data['Bamboo_Coverage'] *= add_noise(0.25, n_samples)\n",
    "\n",
    "data['Vegetation_Diversity_Index'] *= np.exp(-data['Livestock_Density'])\n",
    "data['Vegetation_Diversity_Index'] *= add_noise(0.1, n_samples)\n",
    "\n",
    "data['Water_Source_Availability'] = np.where(data['Annual_Rainfall'] > data['Annual_Rainfall'].mean(), 1, 0)\n",
    "data['Water_Source_Availability'] = np.where(np.random.rand(n_samples) < 0.1, 1 - data['Water_Source_Availability'], data['Water_Source_Availability'])\n",
    "\n",
    "data['Human_Disturbance_Index'] = np.interp(data['Distance_from_Human_Paths'], [0, max(data['Distance_from_Human_Paths'])], [1, 0])\n",
    "data['Human_Disturbance_Index'] *= add_noise(0.25, n_samples)\n",
    "\n",
    "data['Bamboo_Coverage'] *= np.where(data['Slope'] < 20, 1, 0.5)\n",
    "data['Bamboo_Coverage'] *= add_noise(0.3, n_samples)\n",
    "\n",
    "data['Mean_Annual_Temperature'] = 20 - (data['Altitude'] / 200)\n",
    "data['Mean_Annual_Temperature'] += np.random.normal(0, 1, n_samples)\n",
    "\n",
    "# Adding complex noise\n",
    "data['Annual_Rainfall'] = add_complex_noise(data, 'Annual_Rainfall', 0.1, 'Altitude', lambda x: np.exp(-x/2000))\n",
    "\n",
    "# Adding outliers\n",
    "add_outliers(data, 'Annual_Rainfall', 0.01, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Distance_from_Human_Paths</th>\n",
       "      <th>Livestock_Density</th>\n",
       "      <th>Vegetation_Diversity_Index</th>\n",
       "      <th>Water_Source_Availability</th>\n",
       "      <th>Human_Disturbance_Index</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Annual_Rainfall</th>\n",
       "      <th>Bamboo_Coverage</th>\n",
       "      <th>Mean_Annual_Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023.988261</td>\n",
       "      <td>233.915650</td>\n",
       "      <td>3.340433</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>1</td>\n",
       "      <td>1.047134</td>\n",
       "      <td>23.136856</td>\n",
       "      <td>566.418927</td>\n",
       "      <td>10.931381</td>\n",
       "      <td>11.216333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3291.571474</td>\n",
       "      <td>202.416726</td>\n",
       "      <td>2.696428</td>\n",
       "      <td>0.011408</td>\n",
       "      <td>0</td>\n",
       "      <td>1.168012</td>\n",
       "      <td>17.124186</td>\n",
       "      <td>284.616720</td>\n",
       "      <td>49.272585</td>\n",
       "      <td>2.867277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2810.386672</td>\n",
       "      <td>96.885777</td>\n",
       "      <td>4.996221</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>1</td>\n",
       "      <td>1.120357</td>\n",
       "      <td>15.970847</td>\n",
       "      <td>514.922944</td>\n",
       "      <td>75.865653</td>\n",
       "      <td>4.973466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2517.048665</td>\n",
       "      <td>467.312224</td>\n",
       "      <td>3.367542</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826928</td>\n",
       "      <td>17.213960</td>\n",
       "      <td>401.346841</td>\n",
       "      <td>119.316952</td>\n",
       "      <td>6.729508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1543.241009</td>\n",
       "      <td>323.727725</td>\n",
       "      <td>2.785573</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>1</td>\n",
       "      <td>1.285206</td>\n",
       "      <td>11.712508</td>\n",
       "      <td>697.497700</td>\n",
       "      <td>10.044292</td>\n",
       "      <td>12.016826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3086.843174</td>\n",
       "      <td>1047.942515</td>\n",
       "      <td>2.833574</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>0</td>\n",
       "      <td>0.755481</td>\n",
       "      <td>5.319288</td>\n",
       "      <td>278.967119</td>\n",
       "      <td>47.254330</td>\n",
       "      <td>3.012114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3174.519437</td>\n",
       "      <td>23.972588</td>\n",
       "      <td>2.331570</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0</td>\n",
       "      <td>0.896459</td>\n",
       "      <td>17.397050</td>\n",
       "      <td>219.435015</td>\n",
       "      <td>98.759793</td>\n",
       "      <td>4.709172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3282.757413</td>\n",
       "      <td>180.986239</td>\n",
       "      <td>2.879215</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644769</td>\n",
       "      <td>6.531635</td>\n",
       "      <td>292.940575</td>\n",
       "      <td>92.248487</td>\n",
       "      <td>2.835185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2074.473583</td>\n",
       "      <td>292.882361</td>\n",
       "      <td>4.616194</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>0</td>\n",
       "      <td>1.046871</td>\n",
       "      <td>20.329355</td>\n",
       "      <td>508.999587</td>\n",
       "      <td>18.240434</td>\n",
       "      <td>10.360199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1677.708889</td>\n",
       "      <td>94.531000</td>\n",
       "      <td>2.254248</td>\n",
       "      <td>0.028743</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900087</td>\n",
       "      <td>13.951051</td>\n",
       "      <td>888.402052</td>\n",
       "      <td>12.026186</td>\n",
       "      <td>12.430651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Altitude  Distance_from_Human_Paths  Livestock_Density  \\\n",
       "0     2023.988261                 233.915650           3.340433   \n",
       "1     3291.571474                 202.416726           2.696428   \n",
       "2     2810.386672                  96.885777           4.996221   \n",
       "3     2517.048665                 467.312224           3.367542   \n",
       "4     1543.241009                 323.727725           2.785573   \n",
       "...           ...                        ...                ...   \n",
       "9995  3086.843174                1047.942515           2.833574   \n",
       "9996  3174.519437                  23.972588           2.331570   \n",
       "9997  3282.757413                 180.986239           2.879215   \n",
       "9998  2074.473583                 292.882361           4.616194   \n",
       "9999  1677.708889                  94.531000           2.254248   \n",
       "\n",
       "      Vegetation_Diversity_Index  Water_Source_Availability  \\\n",
       "0                       0.004449                          1   \n",
       "1                       0.011408                          0   \n",
       "2                       0.001876                          1   \n",
       "3                       0.004580                          0   \n",
       "4                       0.009529                          1   \n",
       "...                          ...                        ...   \n",
       "9995                    0.007758                          0   \n",
       "9996                    0.013979                          0   \n",
       "9997                    0.013206                          1   \n",
       "9998                    0.001983                          0   \n",
       "9999                    0.028743                          1   \n",
       "\n",
       "      Human_Disturbance_Index      Slope  Annual_Rainfall  Bamboo_Coverage  \\\n",
       "0                    1.047134  23.136856       566.418927        10.931381   \n",
       "1                    1.168012  17.124186       284.616720        49.272585   \n",
       "2                    1.120357  15.970847       514.922944        75.865653   \n",
       "3                    0.826928  17.213960       401.346841       119.316952   \n",
       "4                    1.285206  11.712508       697.497700        10.044292   \n",
       "...                       ...        ...              ...              ...   \n",
       "9995                 0.755481   5.319288       278.967119        47.254330   \n",
       "9996                 0.896459  17.397050       219.435015        98.759793   \n",
       "9997                 0.644769   6.531635       292.940575        92.248487   \n",
       "9998                 1.046871  20.329355       508.999587        18.240434   \n",
       "9999                 0.900087  13.951051       888.402052        12.026186   \n",
       "\n",
       "      Mean_Annual_Temperature  \n",
       "0                   11.216333  \n",
       "1                    2.867277  \n",
       "2                    4.973466  \n",
       "3                    6.729508  \n",
       "4                   12.016826  \n",
       "...                       ...  \n",
       "9995                 3.012114  \n",
       "9996                 4.709172  \n",
       "9997                 2.835185  \n",
       "9998                10.360199  \n",
       "9999                12.430651  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Distance_from_Human_Paths</th>\n",
       "      <th>Livestock_Density</th>\n",
       "      <th>Vegetation_Diversity_Index</th>\n",
       "      <th>Water_Source_Availability</th>\n",
       "      <th>Human_Disturbance_Index</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Annual_Rainfall</th>\n",
       "      <th>Bamboo_Coverage</th>\n",
       "      <th>Mean_Annual_Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023.988261</td>\n",
       "      <td>233.915650</td>\n",
       "      <td>3.340433</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>1</td>\n",
       "      <td>1.047134</td>\n",
       "      <td>23.136856</td>\n",
       "      <td>566.418927</td>\n",
       "      <td>10.931381</td>\n",
       "      <td>11.216333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3291.571474</td>\n",
       "      <td>202.416726</td>\n",
       "      <td>2.696428</td>\n",
       "      <td>0.011408</td>\n",
       "      <td>0</td>\n",
       "      <td>1.168012</td>\n",
       "      <td>17.124186</td>\n",
       "      <td>284.616720</td>\n",
       "      <td>49.272585</td>\n",
       "      <td>2.867277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2810.386672</td>\n",
       "      <td>96.885777</td>\n",
       "      <td>4.996221</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>1</td>\n",
       "      <td>1.120357</td>\n",
       "      <td>15.970847</td>\n",
       "      <td>514.922944</td>\n",
       "      <td>75.865653</td>\n",
       "      <td>4.973466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2517.048665</td>\n",
       "      <td>467.312224</td>\n",
       "      <td>3.367542</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826928</td>\n",
       "      <td>17.213960</td>\n",
       "      <td>401.346841</td>\n",
       "      <td>119.316952</td>\n",
       "      <td>6.729508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1543.241009</td>\n",
       "      <td>323.727725</td>\n",
       "      <td>2.785573</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>1</td>\n",
       "      <td>1.285206</td>\n",
       "      <td>11.712508</td>\n",
       "      <td>697.497700</td>\n",
       "      <td>10.044292</td>\n",
       "      <td>12.016826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3086.843174</td>\n",
       "      <td>1047.942515</td>\n",
       "      <td>2.833574</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>0</td>\n",
       "      <td>0.755481</td>\n",
       "      <td>5.319288</td>\n",
       "      <td>278.967119</td>\n",
       "      <td>47.254330</td>\n",
       "      <td>3.012114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3174.519437</td>\n",
       "      <td>23.972588</td>\n",
       "      <td>2.331570</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0</td>\n",
       "      <td>0.896459</td>\n",
       "      <td>17.397050</td>\n",
       "      <td>219.435015</td>\n",
       "      <td>98.759793</td>\n",
       "      <td>4.709172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3282.757413</td>\n",
       "      <td>180.986239</td>\n",
       "      <td>2.879215</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644769</td>\n",
       "      <td>6.531635</td>\n",
       "      <td>292.940575</td>\n",
       "      <td>92.248487</td>\n",
       "      <td>2.835185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2074.473583</td>\n",
       "      <td>292.882361</td>\n",
       "      <td>4.616194</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>0</td>\n",
       "      <td>1.046871</td>\n",
       "      <td>20.329355</td>\n",
       "      <td>508.999587</td>\n",
       "      <td>18.240434</td>\n",
       "      <td>10.360199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1677.708889</td>\n",
       "      <td>94.531000</td>\n",
       "      <td>2.254248</td>\n",
       "      <td>0.028743</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900087</td>\n",
       "      <td>13.951051</td>\n",
       "      <td>888.402052</td>\n",
       "      <td>12.026186</td>\n",
       "      <td>12.430651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Altitude  Distance_from_Human_Paths  Livestock_Density  \\\n",
       "0     2023.988261                 233.915650           3.340433   \n",
       "1     3291.571474                 202.416726           2.696428   \n",
       "2     2810.386672                  96.885777           4.996221   \n",
       "3     2517.048665                 467.312224           3.367542   \n",
       "4     1543.241009                 323.727725           2.785573   \n",
       "...           ...                        ...                ...   \n",
       "9995  3086.843174                1047.942515           2.833574   \n",
       "9996  3174.519437                  23.972588           2.331570   \n",
       "9997  3282.757413                 180.986239           2.879215   \n",
       "9998  2074.473583                 292.882361           4.616194   \n",
       "9999  1677.708889                  94.531000           2.254248   \n",
       "\n",
       "      Vegetation_Diversity_Index  Water_Source_Availability  \\\n",
       "0                       0.004449                          1   \n",
       "1                       0.011408                          0   \n",
       "2                       0.001876                          1   \n",
       "3                       0.004580                          0   \n",
       "4                       0.009529                          1   \n",
       "...                          ...                        ...   \n",
       "9995                    0.007758                          0   \n",
       "9996                    0.013979                          0   \n",
       "9997                    0.013206                          1   \n",
       "9998                    0.001983                          0   \n",
       "9999                    0.028743                          1   \n",
       "\n",
       "      Human_Disturbance_Index      Slope  Annual_Rainfall  Bamboo_Coverage  \\\n",
       "0                    1.047134  23.136856       566.418927        10.931381   \n",
       "1                    1.168012  17.124186       284.616720        49.272585   \n",
       "2                    1.120357  15.970847       514.922944        75.865653   \n",
       "3                    0.826928  17.213960       401.346841       119.316952   \n",
       "4                    1.285206  11.712508       697.497700        10.044292   \n",
       "...                       ...        ...              ...              ...   \n",
       "9995                 0.755481   5.319288       278.967119        47.254330   \n",
       "9996                 0.896459  17.397050       219.435015        98.759793   \n",
       "9997                 0.644769   6.531635       292.940575        92.248487   \n",
       "9998                 1.046871  20.329355       508.999587        18.240434   \n",
       "9999                 0.900087  13.951051       888.402052        12.026186   \n",
       "\n",
       "      Mean_Annual_Temperature  \n",
       "0                   11.216333  \n",
       "1                    2.867277  \n",
       "2                    4.973466  \n",
       "3                    6.729508  \n",
       "4                   12.016826  \n",
       "...                       ...  \n",
       "9995                 3.012114  \n",
       "9996                 4.709172  \n",
       "9997                 2.835185  \n",
       "9998                10.360199  \n",
       "9999                12.430651  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'Suitable' column estimation -- KMeans**\n",
    "\n",
    "Artificially manipulated to get 30% of environments as suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.7\n",
      "0    0.3\n",
      "Name: Suitable, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giorg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Use KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "clusters = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "# Add the cluster information to the original data\n",
    "data['Cluster'] = clusters\n",
    "\n",
    "# Identify the centroids for each cluster\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Calculate the distance of each point to the centroids\n",
    "distances = kmeans.transform(data_scaled)\n",
    "\n",
    "# Get the distances to the \"farthest\" centroid (assuming cluster 0 is 'unsuitable', cluster 1 is 'suitable')\n",
    "data['Distance_to_Unsuitable'] = distances[:, 0]\n",
    "data['Distance_to_Suitable'] = distances[:, 1]\n",
    "\n",
    "# Determine the 30th percentile threshold for the distance to the 'suitable' centroid\n",
    "threshold = np.percentile(data['Distance_to_Suitable'], 70)  # since we want the closest 30%\n",
    "\n",
    "# Label the data based on the threshold\n",
    "data['Suitable'] = (data['Distance_to_Suitable'] <= threshold).astype(int)\n",
    "\n",
    "# Now, 30% of your data should be labeled as suitable\n",
    "print(data['Suitable'].value_counts(normalize=True))  # Check the proportion of '1's and '0's\n",
    "\n",
    "# Drop the columns not needed anymore\n",
    "data.drop(['Cluster', 'Distance_to_Unsuitable', 'Distance_to_Suitable'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7000\n",
       "0    3000\n",
       "Name: Suitable, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Suitable.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/habitat-suitability.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Logistic Regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 748  165]\n",
      " [ 126 1961]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       913\n",
      "           1       0.92      0.94      0.93      2087\n",
      "\n",
      "    accuracy                           0.90      3000\n",
      "   macro avg       0.89      0.88      0.88      3000\n",
      "weighted avg       0.90      0.90      0.90      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Step 1: Prepare the data\n",
    "# Features matrix 'X' and target variable 'y'\n",
    "X = data.drop('Suitable', axis=1)\n",
    "y = data['Suitable']\n",
    "\n",
    "# Step 2: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Initialize and train the Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 5: Predictions and evaluation\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Model evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transportation Network Structure Dataset Synthesis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def generate_optimization_dataset(n_origins, n_transshipments, n_destinations, total_supply,\n",
    "                                  min_trans_cost = 1, max_trans_cost = 100):\n",
    "    \n",
    "    X = n_origins\n",
    "    Y = n_destinations\n",
    "    Z = n_transshipments\n",
    "    \n",
    "    ## Transportation Costs\n",
    "    # Origin to transshipment\n",
    "    origin_to_transshipment_cost = {}\n",
    "    for i in range(X):\n",
    "        for k in range(Z):\n",
    "            key = f\"{i+1}-{k+1}\"\n",
    "            cost = random.randint(min_trans_cost, max_trans_cost)  # Random uniform\n",
    "            origin_to_transshipment_cost[key] = cost\n",
    "\n",
    "    # Transshipment to destination\n",
    "    transshipment_to_destination_cost = {}\n",
    "    for k in range(Z):\n",
    "        for j in range(Y):\n",
    "            key = f\"{k+1}-{j+1}\"\n",
    "            cost = random.randint(min_trans_cost, max_trans_cost)  # Random uniform\n",
    "            transshipment_to_destination_cost[key] = cost\n",
    "\n",
    "\n",
    "    ## Capacities\n",
    "    # Transhipment capacity\n",
    "    min_capacity_hub = total_supply // Z # To be refined\n",
    "    max_capacity_hub = total_supply // Z + 50\n",
    "\n",
    "    transshipment_capacity = {}\n",
    "    for k in range(Z):\n",
    "        capacity = random.randint(min_capacity_hub, max_capacity_hub)  # Random capacity between 1000 and 5000\n",
    "        transshipment_capacity[f\"{k+1}\"] = capacity\n",
    "\n",
    "    # Destination capacity\n",
    "    min_capacity_destination = 20 # To be refined\n",
    "    max_capacity_destination = total_supply\n",
    "    destination_capacity = {}\n",
    "    for j in range(Y):\n",
    "        capacity = random.randint(min_capacity_destination, max_capacity_destination)\n",
    "        destination_capacity[f\"{j+1}\"] = capacity\n",
    "\n",
    "\n",
    "    ## Supply of origin nodes\n",
    "    origin_supply = {}\n",
    "\n",
    "    proportions = np.random.dirichlet(np.ones(X),size=1)\n",
    "\n",
    "    # Distribute the demand across all origin supply nodes\n",
    "    for i in range(X):\n",
    "        origin_supply[f\"{i+1}\"] = int(proportions[0][i] * total_supply)\n",
    "    \n",
    "    return [origin_to_transshipment_cost, transshipment_to_destination_cost, transshipment_capacity, destination_capacity, origin_supply]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = generate_optimization_dataset(n_origins=10, n_transshipments=5, n_destinations=10000, total_supply=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_to_transshipment_cost = network[0]\n",
    "origin_to_transshipment_cost_df = pd.DataFrame(list(origin_to_transshipment_cost.items()), columns=['Key', 'Value'])\n",
    "origin_to_transshipment_cost_df['Origin'] = origin_to_transshipment_cost_df['Key'].str.split('-').str[0]\n",
    "origin_to_transshipment_cost_df['Hub'] = origin_to_transshipment_cost_df['Key'].str.split('-').str[1]\n",
    "origin_to_transshipment_cost_df = origin_to_transshipment_cost_df.drop('Key', axis=1)\n",
    "\n",
    "\n",
    "transshipment_to_destination_cost = network[1]\n",
    "transshipment_to_destination_cost_df = pd.DataFrame(list(transshipment_to_destination_cost.items()), columns=['Key', 'Value'])\n",
    "transshipment_to_destination_cost_df['Hub'] = transshipment_to_destination_cost_df['Key'].str.split('-').str[0]\n",
    "transshipment_to_destination_cost_df['Destination'] = transshipment_to_destination_cost_df['Key'].str.split('-').str[1]\n",
    "transshipment_to_destination_cost_df = transshipment_to_destination_cost_df.drop('Key', axis=1)\n",
    "\n",
    "transshipment_capacity = network[2] \n",
    "transshipment_capacity_df = pd.DataFrame(list(transshipment_capacity.items()), columns=['Hub', 'Value'])\n",
    "\n",
    "destination_capacity = network[3]\n",
    "destination_capacity_df = pd.DataFrame(list(destination_capacity.items()), columns=['Destination', 'Value'])\n",
    "\n",
    "origin_supply = network[4]\n",
    "origin_supply_df = pd.DataFrame(list(origin_supply.items()), columns=['Origin', 'Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50050"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(origin_to_transshipment_cost_df) + len(transshipment_to_destination_cost_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_to_transshipment_cost_df.to_csv('data/opti-origin_to_transshipment_cost.csv', index=False)\n",
    "transshipment_to_destination_cost_df.to_csv('data/opti-transshipment_to_destination_cost.csv', index=False)  \n",
    "transshipment_capacity_df.to_csv('data/opti-transshipment_capacity.csv', index=False)\n",
    "destination_capacity_df.to_csv('data/opti-destination_capacity.csv', index=False)\n",
    "origin_supply_df.to_csv('data/opti-origin_supply.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
